{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Hyperliquid S3 Data Sampler\n",
    "\n",
    "This notebook downloads sample data from each Hyperliquid S3 bucket to help understand the data structure.\n",
    "\n",
    "## Available Buckets\n",
    "\n",
    "| Bucket | Contents | Format |\n",
    "|--------|----------|--------|\n",
    "| `hyperliquid-archive` | L2 book snapshots, asset contexts | LZ4 compressed |\n",
    "| `hl-mainnet-node-data` | Fills, trades, explorer blocks | LZ4/JSON |\n",
    "| `hl-mainnet-evm-blocks` | HyperEVM block data | MessagePack + LZ4 |\n",
    "\n",
    "Samples are saved to `../hyperliquid_samples/` mirroring the S3 structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport json\nimport lz4.frame\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n\nSAMPLES_DIR = Path(\"../hyperliquid_samples\")\nSAMPLES_DIR.mkdir(exist_ok=True)\n\ndef run_aws(cmd: str) -> str:\n    \"\"\"Run AWS CLI command with requester-pays.\"\"\"\n    full_cmd = f\"aws s3 {cmd} --request-payer requester\"\n    result = subprocess.run(full_cmd, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(f\"Error: {result.stderr}\")\n        return \"\"\n    return result.stdout\n\ndef list_s3(bucket: str, prefix: str = \"\", max_items: int = 20) -> list[str]:\n    \"\"\"List objects in S3 bucket.\"\"\"\n    output = run_aws(f\"ls s3://{bucket}/{prefix}\")\n    lines = [l.strip() for l in output.strip().split(\"\\n\") if l.strip()][:max_items]\n    for line in lines:\n        print(line)\n    return lines\n\ndef download_sample(bucket: str, key: str, local_subdir: str = \"\") -> Path:\n    \"\"\"Download a file from S3 to samples directory.\"\"\"\n    local_dir = SAMPLES_DIR / bucket / local_subdir\n    local_dir.mkdir(parents=True, exist_ok=True)\n    local_path = local_dir / Path(key).name\n    \n    if local_path.exists():\n        print(f\"Already exists: {local_path}\")\n        return local_path\n    \n    print(f\"Downloading s3://{bucket}/{key}...\")\n    run_aws(f\"cp s3://{bucket}/{key} {local_path}\")\n    print(f\"Saved to: {local_path}\")\n    return local_path\n\ndef detect_format(data: bytes) -> str:\n    \"\"\"Detect file format from content.\"\"\"\n    try:\n        text = data[:1000].decode(\"utf-8\", errors=\"ignore\").strip()\n        # Check if it's CSV (has commas and newlines, first line looks like headers)\n        if \",\" in text and \"\\n\" in text:\n            first_line = text.split(\"\\n\")[0]\n            if all(c.isalnum() or c in \",_\" for c in first_line.replace(\" \", \"\")):\n                return \"csv\"\n        # Check if it's JSON or JSONL\n        if text.startswith(\"{\") or text.startswith(\"[\"):\n            return \"json\"\n        if text and text[0] == \"{\":\n            return \"jsonl\"\n    except:\n        pass\n    return \"txt\"\n\ndef decompress_lz4(path: Path, force_ext: str = None) -> Path:\n    \"\"\"Decompress LZ4 file and rename with proper extension.\n    \n    Args:\n        path: Path to .lz4 file\n        force_ext: Force a specific extension (e.g., \"json\", \"csv\")\n    \n    Returns:\n        Path to decompressed file with appropriate extension\n    \"\"\"\n    if path.suffix != \".lz4\":\n        return path\n    \n    # Decompress\n    with open(path, \"rb\") as f_in:\n        data = lz4.frame.decompress(f_in.read())\n    \n    # Determine output extension\n    base = path.with_suffix(\"\")  # Remove .lz4\n    \n    if force_ext:\n        ext = force_ext\n    elif base.suffix in [\".csv\", \".json\", \".jsonl\", \".txt\"]:\n        # Already has a good extension (e.g., file.csv.lz4 -> file.csv)\n        ext = None  # Keep as-is\n    else:\n        # Detect format from content\n        ext = detect_format(data)\n    \n    if ext:\n        output_path = base.with_suffix(f\".{ext}\")\n    else:\n        output_path = base\n    \n    if output_path.exists():\n        print(f\"Already decompressed: {output_path}\")\n        return output_path\n    \n    with open(output_path, \"wb\") as f_out:\n        f_out.write(data)\n    \n    print(f\"Decompressed: {output_path}\")\n    return output_path\n\ndef decode_msgpack_to_json(path: Path) -> Path:\n    \"\"\"Decode MessagePack (.rmp.lz4) file to JSON.\"\"\"\n    import msgpack\n    \n    # Read and decompress\n    with open(path, \"rb\") as f:\n        compressed = f.read()\n    \n    decompressed = lz4.frame.decompress(compressed)\n    data = msgpack.unpackb(decompressed, raw=False)\n    \n    # Save as JSON\n    json_path = path.with_suffix(\"\").with_suffix(\".json\")  # .rmp.lz4 -> .json\n    \n    if json_path.exists():\n        print(f\"Already decoded: {json_path}\")\n        return json_path\n    \n    with open(json_path, \"w\") as f:\n        json.dump(data, f, indent=2, default=str)\n    \n    print(f\"Decoded to JSON: {json_path}\")\n    return json_path\n\ndef preview_file(path: Path, lines: int = 20) -> None:\n    \"\"\"Preview first N lines of a file.\"\"\"\n    with open(path, \"r\", errors=\"replace\") as f:\n        for i, line in enumerate(f):\n            if i >= lines:\n                print(f\"... ({lines} of many lines shown)\")\n                break\n            print(line.rstrip())\n\nprint(\"Setup complete. Samples will be saved to:\", SAMPLES_DIR.resolve())"
  },
  {
   "cell_type": "markdown",
   "id": "archive-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. hyperliquid-archive\n",
    "\n",
    "Contains L2 orderbook snapshots and asset context data. Updated ~monthly.\n",
    "\n",
    "**Structure:**\n",
    "```\n",
    "hyperliquid-archive/\n",
    "├── market_data/\n",
    "│   └── [YYYYMMDD]/\n",
    "│       └── [hour 0-23]/\n",
    "│           └── l2Book/\n",
    "│               └── [COIN].lz4\n",
    "└── asset_ctxs/\n",
    "    └── [YYYYMMDD].csv.lz4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "archive-explore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "hyperliquid-archive - Top level\n",
      "============================================================\n",
      "PRE Testnet/\n",
      "PRE asset_ctxs/\n",
      "PRE market_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE Testnet/', 'PRE asset_ctxs/', 'PRE market_data/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore hyperliquid-archive structure\n",
    "print(\"=\" * 60)\n",
    "print(\"hyperliquid-archive - Top level\")\n",
    "print(\"=\" * 60)\n",
    "list_s3(\"hyperliquid-archive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "archive-market-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dates in market_data/:\n",
      "PRE 20230415/\n",
      "PRE 20230416/\n",
      "PRE 20230417/\n",
      "PRE 20230418/\n",
      "PRE 20230419/\n",
      "PRE 20230420/\n",
      "PRE 20230421/\n",
      "PRE 20230422/\n",
      "PRE 20230423/\n",
      "PRE 20230424/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE 20230415/',\n",
       " 'PRE 20230416/',\n",
       " 'PRE 20230417/',\n",
       " 'PRE 20230418/',\n",
       " 'PRE 20230419/',\n",
       " 'PRE 20230420/',\n",
       " 'PRE 20230421/',\n",
       " 'PRE 20230422/',\n",
       " 'PRE 20230423/',\n",
       " 'PRE 20230424/']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List available dates in market_data\n",
    "print(\"Available dates in market_data/:\")\n",
    "list_s3(\"hyperliquid-archive\", \"market_data/\", max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "archive-sample-l2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coins available for 20240101 hour 12:\n",
      "2024-01-10 13:34:55     249607 AAVE.lz4\n",
      "2024-01-10 13:34:55     503267 ACE.lz4\n",
      "2024-01-10 13:34:55     304366 ADA.lz4\n",
      "2024-01-10 13:34:55     210242 APE.lz4\n",
      "2024-01-10 13:34:55     340025 APT.lz4\n",
      "2024-01-10 13:34:55     367217 ARB.lz4\n",
      "2024-01-10 13:34:55     266178 ARK.lz4\n",
      "2024-01-10 13:34:55     270370 ATOM.lz4\n",
      "2024-01-10 13:34:55     441728 AVAX.lz4\n",
      "2024-01-10 13:34:55     237988 BADGER.lz4\n",
      "2024-01-10 13:34:55     154178 BANANA.lz4\n",
      "2024-01-10 13:34:55     267246 BCH.lz4\n",
      "2024-01-10 13:34:55     370771 BIGTIME.lz4\n",
      "2024-01-10 13:34:55     316714 BLUR.lz4\n",
      "2024-01-10 13:34:55     301069 BLZ.lz4\n",
      "2024-01-10 13:34:55     249844 BNB.lz4\n",
      "2024-01-10 13:34:55     235714 BNT.lz4\n",
      "2024-01-10 13:34:55     461182 BSV.lz4\n",
      "2024-01-10 13:34:55     309355 BTC.lz4\n",
      "2024-01-10 13:34:55     256782 CAKE.lz4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2024-01-10 13:34:55     249607 AAVE.lz4',\n",
       " '2024-01-10 13:34:55     503267 ACE.lz4',\n",
       " '2024-01-10 13:34:55     304366 ADA.lz4',\n",
       " '2024-01-10 13:34:55     210242 APE.lz4',\n",
       " '2024-01-10 13:34:55     340025 APT.lz4',\n",
       " '2024-01-10 13:34:55     367217 ARB.lz4',\n",
       " '2024-01-10 13:34:55     266178 ARK.lz4',\n",
       " '2024-01-10 13:34:55     270370 ATOM.lz4',\n",
       " '2024-01-10 13:34:55     441728 AVAX.lz4',\n",
       " '2024-01-10 13:34:55     237988 BADGER.lz4',\n",
       " '2024-01-10 13:34:55     154178 BANANA.lz4',\n",
       " '2024-01-10 13:34:55     267246 BCH.lz4',\n",
       " '2024-01-10 13:34:55     370771 BIGTIME.lz4',\n",
       " '2024-01-10 13:34:55     316714 BLUR.lz4',\n",
       " '2024-01-10 13:34:55     301069 BLZ.lz4',\n",
       " '2024-01-10 13:34:55     249844 BNB.lz4',\n",
       " '2024-01-10 13:34:55     235714 BNT.lz4',\n",
       " '2024-01-10 13:34:55     461182 BSV.lz4',\n",
       " '2024-01-10 13:34:55     309355 BTC.lz4',\n",
       " '2024-01-10 13:34:55     256782 CAKE.lz4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample: L2 Book snapshot for BTC\n",
    "# Pick a date that exists (adjust based on list above)\n",
    "SAMPLE_DATE = \"20240101\"  # Adjust to an available date\n",
    "SAMPLE_HOUR = \"12\"\n",
    "SAMPLE_COIN = \"BTC\"\n",
    "\n",
    "# Check what coins are available\n",
    "print(f\"Coins available for {SAMPLE_DATE} hour {SAMPLE_HOUR}:\")\n",
    "list_s3(\"hyperliquid-archive\", f\"market_data/{SAMPLE_DATE}/{SAMPLE_HOUR}/l2Book/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "archive-download-l2",
   "metadata": {},
   "outputs": [],
   "source": "# Download and inspect L2 book sample\nl2_key = f\"market_data/{SAMPLE_DATE}/{SAMPLE_HOUR}/l2Book/{SAMPLE_COIN}.lz4\"\nl2_path = download_sample(\"hyperliquid-archive\", l2_key, f\"market_data/{SAMPLE_DATE}/{SAMPLE_HOUR}/l2Book\")\n\nif l2_path.exists():\n    # L2 book files are JSON lines\n    decompressed = decompress_lz4(l2_path, force_ext=\"jsonl\")\n    print(\"\\n\" + \"=\" * 60)\n    print(f\"L2 Book Data Structure ({SAMPLE_COIN}):\")\n    print(\"=\" * 60)\n    preview_file(decompressed, lines=30)"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "archive-asset-ctxs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available asset_ctxs files:\n",
      "2024-12-27 02:36:59    1004923 20230520.csv.lz4\n",
      "2024-12-27 02:36:59    1164671 20230521.csv.lz4\n",
      "2024-12-27 02:36:59    1215123 20230522.csv.lz4\n",
      "2024-12-27 02:36:59    1201427 20230523.csv.lz4\n",
      "2024-12-27 02:36:59    1344355 20230524.csv.lz4\n",
      "2024-12-27 02:36:59    1536620 20230525.csv.lz4\n",
      "2024-12-27 02:36:59    1511494 20230526.csv.lz4\n",
      "2024-12-27 02:36:59    1393419 20230527.csv.lz4\n",
      "2024-12-27 02:36:59    1467243 20230528.csv.lz4\n",
      "2024-12-27 02:37:00    1503738 20230529.csv.lz4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2024-12-27 02:36:59    1004923 20230520.csv.lz4',\n",
       " '2024-12-27 02:36:59    1164671 20230521.csv.lz4',\n",
       " '2024-12-27 02:36:59    1215123 20230522.csv.lz4',\n",
       " '2024-12-27 02:36:59    1201427 20230523.csv.lz4',\n",
       " '2024-12-27 02:36:59    1344355 20230524.csv.lz4',\n",
       " '2024-12-27 02:36:59    1536620 20230525.csv.lz4',\n",
       " '2024-12-27 02:36:59    1511494 20230526.csv.lz4',\n",
       " '2024-12-27 02:36:59    1393419 20230527.csv.lz4',\n",
       " '2024-12-27 02:36:59    1467243 20230528.csv.lz4',\n",
       " '2024-12-27 02:37:00    1503738 20230529.csv.lz4']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample: Asset contexts\n",
    "print(\"Available asset_ctxs files:\")\n",
    "list_s3(\"hyperliquid-archive\", \"asset_ctxs/\", max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "archive-download-ctx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading s3://hyperliquid-archive/asset_ctxs/20240101.csv.lz4...\n",
      "Saved to: ../hyperliquid_samples/hyperliquid-archive/asset_ctxs/20240101.csv.lz4\n",
      "Decompressed: ../hyperliquid_samples/hyperliquid-archive/asset_ctxs/20240101.csv\n",
      "\n",
      "============================================================\n",
      "Asset Context Data Structure:\n",
      "============================================================\n",
      "time,coin,funding,open_interest,prev_day_px,day_ntl_vlm,premium,oracle_px,mark_px,mid_px,impact_bid_px,impact_ask_px\n",
      "2024-01-01T00:00:00Z,AAVE,0.00002789,1075.9,111.09,1759054.2941,0.00072316,108.69,108.79,108.765,108.75,108.7872\n",
      "2024-01-01T00:00:00Z,ACE,0.00004605,9238.23,10.331,1168558.484093,0.00086837,9.3278,9.331,9.3361,9.334,9.3378\n",
      "2024-01-01T00:00:00Z,ADA,0.0000125,725829,0.60135,723752.77572,0.00048152,0.59395,0.59424,0.594245,0.594144,0.594328\n",
      "2024-01-01T00:00:00Z,APE,0.00013221,136489.6,1.6509,453141.36398,0.00155768,1.621,1.6235,1.62365,1.62285,1.6242\n",
      "2024-01-01T00:00:00Z,APT,0.00018119,13074.82,9.3941,851013.11729,0.00194953,9.3869,9.4035,9.4051,9.4031,9.4073\n",
      "2024-01-01T00:00:00Z,ARB,0.00008562,1043726.6,1.4815,6696561.12307,0.00118499,1.5612,1.563,1.56305,1.5627,1.5634\n",
      "2024-01-01T00:00:00Z,ARK,0.00008812,117575,0.94524,190678.45803,0.00120492,0.9262,0.92758,0.92726,0.927114,0.927518\n",
      "2024-01-01T00:00:00Z,ATOM,0.00007901,47131.56,10.739,868043.92614,0.00113208,10.6,10.611,10.612,10.61,10.614\n",
      "2024-01-01T00:00:00Z,AVAX,0.0000125,19645.8,39.368,3140363.75726,0.00042786,38.564,38.582,38.581,38.577,38.584\n",
      "2024-01-01T00:00:00Z,BADGER,0.00017827,33509,4.109,244596.10925,0.00192618,3.969,3.9753,3.9766,3.97524,3.97805\n",
      "2024-01-01T00:00:00Z,BANANA,0.00012039,2584.8,12.85,50108.7267,0.00146308,11.797,11.798,11.8,11.74595,11.88257\n",
      "2024-01-01T00:00:00Z,BCH,0.00003137,472.384,270.78,1000134.21161,0.00075098,259.66,259.91,259.855,259.83,259.88\n",
      "2024-01-01T00:00:00Z,BIGTIME,0.0000125,376185,0.51476,697172.28275,0.00030535,0.4896,0.49012,0.48987,0.489483,0.490016\n",
      "2024-01-01T00:00:00Z,BLUR,0.00002048,879064,0.47788,773132.47731,0.00066386,0.4632,0.46347,0.463525,0.463425,0.46359\n",
      "2024-01-01T00:00:00Z,BLZ,0.00017343,322982,0.34672,217690.72728,0.00188741,0.3375,0.33799,0.33817,0.338054,0.33822\n",
      "2024-01-01T00:00:00Z,BNB,-0.00015535,3138.819,316.76,1334585.27169,-0.00174277,311.86,311.3,311.29,311.25,311.383\n",
      "2024-01-01T00:00:00Z,BNT,0.00007371,347445,0.73594,223338.83545,0.00108968,0.7337,0.73422,0.7345,0.734359,0.73464\n",
      "2024-01-01T00:00:00Z,BSV,-0.00018758,2639.69,93.374,598373.19474,-0.00200062,96.02,95.84,95.8315,95.7789,95.8769\n",
      "2024-01-01T00:00:00Z,BTC,0.00007127,284.01343,42184,34508403.68744999,0.00107014,42284,42330,42330,42324.1,42334.4\n",
      "... (20 of many lines shown)\n"
     ]
    }
   ],
   "source": [
    "# Download and inspect asset context sample\n",
    "ctx_key = f\"asset_ctxs/{SAMPLE_DATE}.csv.lz4\"  # Adjust date if needed\n",
    "ctx_path = download_sample(\"hyperliquid-archive\", ctx_key, \"asset_ctxs\")\n",
    "\n",
    "if ctx_path.exists():\n",
    "    decompressed = decompress_lz4(ctx_path)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Asset Context Data Structure:\")\n",
    "    print(\"=\" * 60)\n",
    "    preview_file(decompressed, lines=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "node-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. hl-mainnet-node-data\n",
    "\n",
    "Contains fill records, trades, and explorer data from Hyperliquid nodes.\n",
    "\n",
    "**Structure:**\n",
    "```\n",
    "hl-mainnet-node-data/\n",
    "├── node_fills_by_block/    # Modern format - fills batched by block\n",
    "├── node_fills/             # Legacy format - individual fills\n",
    "├── node_trades/            # Legacy trade records\n",
    "├── explorer_blocks/        # Block data for explorer\n",
    "└── replica_cmds/           # L1 transaction commands\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "node-explore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "hl-mainnet-node-data - Top level\n",
      "============================================================\n",
      "PRE explorer_blocks/\n",
      "PRE misc_events_by_block/\n",
      "PRE node_fills/\n",
      "PRE node_fills_by_block/\n",
      "PRE node_trades/\n",
      "PRE replica_cmds/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE explorer_blocks/',\n",
       " 'PRE misc_events_by_block/',\n",
       " 'PRE node_fills/',\n",
       " 'PRE node_fills_by_block/',\n",
       " 'PRE node_trades/',\n",
       " 'PRE replica_cmds/']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore hl-mainnet-node-data structure\n",
    "print(\"=\" * 60)\n",
    "print(\"hl-mainnet-node-data - Top level\")\n",
    "print(\"=\" * 60)\n",
    "list_s3(\"hl-mainnet-node-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "node-fills-by-block",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_fills_by_block/ structure:\n",
      "PRE hourly/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE hourly/']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore node_fills_by_block (modern format)\n",
    "print(\"node_fills_by_block/ structure:\")\n",
    "list_s3(\"hl-mainnet-node-data\", \"node_fills_by_block/\", max_items=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "node-download-fills",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample files available:\n",
      "  node_fills_by_block/hourly/20250727/10.lz4\n",
      "  node_fills_by_block/hourly/20250727/11.lz4\n",
      "  node_fills_by_block/hourly/20250727/12.lz4\n",
      "  node_fills_by_block/hourly/20250727/13.lz4\n",
      "  node_fills_by_block/hourly/20250727/14.lz4\n"
     ]
    }
   ],
   "source": [
    "# Download a sample fills file\n",
    "# First, find an available file\n",
    "output = run_aws(\"ls s3://hl-mainnet-node-data/node_fills_by_block/ --recursive\")\n",
    "files = [l.split()[-1] for l in output.strip().split(\"\\n\") if l.strip()][:5]\n",
    "print(\"Sample files available:\")\n",
    "for f in files:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "node-inspect-fills",
   "metadata": {},
   "outputs": [],
   "source": "# Download and inspect first available fills file\nif files:\n    sample_key = files[0]\n    fills_path = download_sample(\"hl-mainnet-node-data\", sample_key, \"node_fills_by_block\")\n    \n    if fills_path.exists():\n        # Node fills are JSON lines\n        if fills_path.suffix == \".lz4\":\n            fills_path = decompress_lz4(fills_path, force_ext=\"jsonl\")\n        \n        print(\"\\n\" + \"=\" * 60)\n        print(\"Node Fills by Block Data Structure:\")\n        print(\"=\" * 60)\n        preview_file(fills_path, lines=30)"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "node-legacy-fills",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_fills/ (legacy format):\n",
      "PRE hourly/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE hourly/']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore legacy node_fills format\n",
    "print(\"node_fills/ (legacy format):\")\n",
    "list_s3(\"hl-mainnet-node-data\", \"node_fills/\", max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "node-trades",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_trades/:\n",
      "PRE hourly/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE hourly/']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore node_trades\n",
    "print(\"node_trades/:\")\n",
    "list_s3(\"hl-mainnet-node-data\", \"node_trades/\", max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "node-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explorer_blocks/:\n",
      "PRE 0/\n",
      "PRE 100000000/\n",
      "PRE 200000000/\n",
      "PRE 300000000/\n",
      "PRE 400000000/\n",
      "PRE 500000000/\n",
      "PRE 600000000/\n",
      "PRE 700000000/\n",
      "PRE 800000000/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE 0/',\n",
       " 'PRE 100000000/',\n",
       " 'PRE 200000000/',\n",
       " 'PRE 300000000/',\n",
       " 'PRE 400000000/',\n",
       " 'PRE 500000000/',\n",
       " 'PRE 600000000/',\n",
       " 'PRE 700000000/',\n",
       " 'PRE 800000000/']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore explorer_blocks\n",
    "print(\"explorer_blocks/:\")\n",
    "list_s3(\"hl-mainnet-node-data\", \"explorer_blocks/\", max_items=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evm-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. hl-mainnet-evm-blocks\n",
    "\n",
    "Contains HyperEVM block data for indexing without running a node.\n",
    "\n",
    "**Structure:**\n",
    "```\n",
    "hl-mainnet-evm-blocks/\n",
    "└── [prefix]/\n",
    "    └── [range]/\n",
    "        └── [block_number].rmp.lz4\n",
    "```\n",
    "\n",
    "Files are MessagePack format, LZ4 compressed. Block numbers are predictably indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "evm-explore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "hl-mainnet-evm-blocks - Top level\n",
      "============================================================\n",
      "PRE 0/\n",
      "PRE 1000000/\n",
      "PRE 10000000/\n",
      "PRE 11000000/\n",
      "PRE 12000000/\n",
      "PRE 13000000/\n",
      "PRE 14000000/\n",
      "PRE 15000000/\n",
      "PRE 16000000/\n",
      "PRE 17000000/\n",
      "PRE 18000000/\n",
      "PRE 19000000/\n",
      "PRE 2000000/\n",
      "PRE 20000000/\n",
      "PRE 3000000/\n",
      "PRE 4000000/\n",
      "PRE 5000000/\n",
      "PRE 6000000/\n",
      "PRE 7000000/\n",
      "PRE 8000000/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE 0/',\n",
       " 'PRE 1000000/',\n",
       " 'PRE 10000000/',\n",
       " 'PRE 11000000/',\n",
       " 'PRE 12000000/',\n",
       " 'PRE 13000000/',\n",
       " 'PRE 14000000/',\n",
       " 'PRE 15000000/',\n",
       " 'PRE 16000000/',\n",
       " 'PRE 17000000/',\n",
       " 'PRE 18000000/',\n",
       " 'PRE 19000000/',\n",
       " 'PRE 2000000/',\n",
       " 'PRE 20000000/',\n",
       " 'PRE 3000000/',\n",
       " 'PRE 4000000/',\n",
       " 'PRE 5000000/',\n",
       " 'PRE 6000000/',\n",
       " 'PRE 7000000/',\n",
       " 'PRE 8000000/']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore hl-mainnet-evm-blocks structure\n",
    "print(\"=\" * 60)\n",
    "print(\"hl-mainnet-evm-blocks - Top level\")\n",
    "print(\"=\" * 60)\n",
    "list_s3(\"hl-mainnet-evm-blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "evm-dive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring nested structure:\n",
      "PRE 0/\n",
      "PRE 1000/\n",
      "PRE 10000/\n",
      "PRE 100000/\n",
      "PRE 101000/\n",
      "PRE 102000/\n",
      "PRE 103000/\n",
      "PRE 104000/\n",
      "PRE 105000/\n",
      "PRE 106000/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRE 0/',\n",
       " 'PRE 1000/',\n",
       " 'PRE 10000/',\n",
       " 'PRE 100000/',\n",
       " 'PRE 101000/',\n",
       " 'PRE 102000/',\n",
       " 'PRE 103000/',\n",
       " 'PRE 104000/',\n",
       " 'PRE 105000/',\n",
       " 'PRE 106000/']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dive into structure\n",
    "print(\"Exploring nested structure:\")\n",
    "list_s3(\"hl-mainnet-evm-blocks\", \"0/\", max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "evm-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample EVM block files:\n",
      "  0/0/1.rmp.lz4\n",
      "  0/0/10.rmp.lz4\n",
      "  0/0/100.rmp.lz4\n"
     ]
    }
   ],
   "source": [
    "# Download a sample EVM block\n",
    "import msgpack\n",
    "\n",
    "# Find a sample block file\n",
    "output = run_aws(\"ls s3://hl-mainnet-evm-blocks/0/0/ --recursive\")\n",
    "evm_files = [l.split()[-1] for l in output.strip().split(\"\\n\") if l.strip() and \".rmp.lz4\" in l][:3]\n",
    "print(\"Sample EVM block files:\")\n",
    "for f in evm_files:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evm-inspect",
   "metadata": {},
   "outputs": [],
   "source": "# Download and decode EVM block to JSON\nif evm_files:\n    evm_key = evm_files[0]\n    evm_path = download_sample(\"hl-mainnet-evm-blocks\", evm_key, \"blocks\")\n    \n    if evm_path.exists():\n        # Decode MessagePack to JSON\n        json_path = decode_msgpack_to_json(evm_path)\n        \n        print(\"\\n\" + \"=\" * 60)\n        print(\"EVM Block Data Structure:\")\n        print(\"=\" * 60)\n        preview_file(json_path, lines=50)"
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": "---\n## Summary: What's in Each Bucket\n\n### hyperliquid-archive\n- **market_data/**: L2 orderbook snapshots per coin per hour\n  - Format: JSON lines → saved as `.jsonl`\n  - Use case: Historical orderbook analysis, liquidity studies\n- **asset_ctxs/**: Daily asset context snapshots\n  - Format: CSV → saved as `.csv`\n  - Use case: Understanding asset parameters over time\n\n### hl-mainnet-node-data  \n- **node_fills_by_block/**: Trade fills grouped by block (modern)\n  - Format: JSON lines → saved as `.jsonl`\n  - Use case: Trade analysis, volume studies\n- **node_fills/**: Legacy individual fill records\n- **node_trades/**: Legacy trade format\n- **explorer_blocks/**: Block data for explorer indexing\n- **replica_cmds/**: L1 transaction commands\n\n### hl-mainnet-evm-blocks\n- EVM block data in MessagePack format → decoded to `.json`\n- Use case: Indexing HyperEVM without running a node\n\n---\n### File Extensions After Download\n| Original | Decompressed |\n|----------|--------------|\n| `BTC.lz4` | `BTC.jsonl` |\n| `20240101.csv.lz4` | `20240101.csv` |\n| `10.lz4` (fills) | `10.jsonl` |\n| `1.rmp.lz4` (EVM) | `1.json` |\n\nCheck `../hyperliquid_samples/` for downloaded files organized by bucket."
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "show-samples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded samples:\n",
      "============================================================\n",
      "  README.md  (1.2 KB)\n",
      "  hl-mainnet-evm-blocks/blocks/1.rmp.lz4  (0.5 KB)\n",
      "  hl-mainnet-node-data/node_fills_by_block/10  (102161.9 KB)\n",
      "  hl-mainnet-node-data/node_fills_by_block/10.lz4  (20848.9 KB)\n",
      "  hyperliquid-archive/asset_ctxs/20240101.csv  (16072.7 KB)\n",
      "  hyperliquid-archive/asset_ctxs/20240101.csv.lz4  (5879.0 KB)\n",
      "  hyperliquid-archive/market_data/20240101/12/l2Book/BTC  (8963.4 KB)\n",
      "  hyperliquid-archive/market_data/20240101/12/l2Book/BTC.lz4  (302.1 KB)\n"
     ]
    }
   ],
   "source": [
    "# Show what we've downloaded\n",
    "print(\"Downloaded samples:\")\n",
    "print(\"=\" * 60)\n",
    "for path in sorted(SAMPLES_DIR.rglob(\"*\")):\n",
    "    if path.is_file():\n",
    "        size_kb = path.stat().st_size / 1024\n",
    "        rel_path = path.relative_to(SAMPLES_DIR)\n",
    "        print(f\"  {rel_path}  ({size_kb:.1f} KB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}